1. 为什么 NL2SQL 会产生幻觉？

   | 问题来源               | 说明                                                         |
   | ---------------------- | ------------------------------------------------------------ |
   | ❗自然语言模糊          | 用户的问题经常是不精确的，例如“近三年销售最多的客户有哪些？”——这个问题涉及“时间窗口”、“聚合”、“排序”等多个隐含约定 |
   | ❗数据库 schema 复杂    | 数据库可能有大量表、字段、外键，模型不清楚这些结构之间的真实语义关系 |
   | ❗训练数据有限          | 大多数开源数据集（如 Spider、WikiSQL）都较小，无法覆盖企业真实数据库的多样性与复杂性 |
   | ❗模型泛化差            | 即使是 GPT-4，在真实数据库上也常常产生“语义合理但逻辑错误”的 SQL |
   | ❗缺乏 schema-awareness | 即使模型接收了表结构，理解表之间关系仍然困难，容易引入非存在字段或错误 join 逻辑 |

2. NL2SQL 的典型幻觉表现

   | 幻觉类型       | 示例                                               |
   | -------------- | -------------------------------------------------- |
   | ❌ 不存在的字段 | SQL 中使用了 schema 中没有的字段名                 |
   | ❌ 错误的表连接 | 把没有关联的表 join 到一起                         |
   | ❌ 逻辑错误     | 比如“总销售额最高的客户”，结果返回了客户数量最多的 |
   | ❌ 错误聚合     | 将 sum 用成 count，或 group by 漏掉某些字段        |
   | ❌ 时间逻辑不符 | “近三年”被写成了“从 2023 年起的所有年份”           |

3.实际落地难点

| 维度               | 挑战                                                         |
| ------------------ | ------------------------------------------------------------ |
| 🤯 数据库异构性     | 不同业务的数据库结构千差万别（字段命名风格、业务逻辑、冗余程度） |
| 🤯 安全性需求       | 自动生成 SQL 一旦出错，可能导致数据泄露、误查询或数据库异常压力 |
| 🤯 工程成本高       | 需要大量 schema 注解、prompt 工程、规则约束或后处理机制保障准确性 |
| 🤯 无法 trust model | 模型一旦输出一个逻辑错误但语法正确的 SQL，后果难以预料       |

4.能不能落地？——「受控」场景是可以的

 可以落地的前提场景：

| 可控条件       | 示例                                                         |
| -------------- | ------------------------------------------------------------ |
| ✅ schema 简单  | 只有 2-3 张表，字段命名规范（如 BI 分析模型）                |
| ✅ 问句模板化   | 问题类型有固定槽位、规则（如：“查 X 时间段 Y 地区的 Z 指标”） |
| ✅ 用户可校对   | SQL 被翻译出来后，由用户二次确认                             |
| ✅ 领域受限     | 例如只对医疗、财务、物流等限定领域建模                       |
| ✅ 结合规则系统 | 使用静态规则修正不合理结构、拼接 Join 关系                   |

###  实际落地案例：

- **腾讯云智能 BI / 字节火山引擎**：用 LLM 辅助生成 SQL，结合 schema 引导 + 规则限制 + 人工校正
- **Databricks + LLM**：限制在 notebook 场景中解释 SQL 或帮助补全部分 SQL
- **PromptLayer / Text2SQL with Augmented Retrieval**：利用 schema 检索+约束生成

## 结论总结：

> **NL2SQL 不是“完全不能落地”，而是在没有结构约束和场景受限的情况下，幻觉问题太严重而难以直接生产使用。**

- ✅ 它可以在“结构受控 + 数据受限 + 用户可反馈”的场景中落地
- ❌ 在“通用自然语言 + 任意复杂数据库”中直接生成高质量 SQL 是非常困难的
- 🧠 幻觉（hallucination）是其最大工程障碍，未来需要结合 schema 检索、规则引导与用户交互来缓解

**PS**：在我试图完成nl2sql任务时，我发现了一个很有代表性严重幻觉：

```json
{
        "nl":"易方达基金管理有限公司2020年成立了多少基金?",
        "sql":"SELECT COUNT(*) FROM `基金基本信息` WHERE `管理人` = '易方达基金管理有限公司' AND `成立日期` BETWEEN '20200101' AND '20231231';"
}
```

这种没有语法错误、能识别表名和字段且能执行并返回结果的幻觉(要求搜索2020年的数据，却2020-2023年之间所有的数据)令人心碎